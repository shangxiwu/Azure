{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 執行自訂視覺物件偵測服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry, Region\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "# ENDPOINT = #\"<your API endpoint>\" \n",
    "train_ENDPOINT = 'https://westus2.api.cognitive.microsoft.com/' #\"<your API endpoint>\" \n",
    "predi_ENDPOINT = 'https://cvpre.cognitiveservices.azure.com/' #\"<your API endpoint>\" \n",
    "\n",
    "# Replace with a valid key\n",
    "training_key = 'd8803189a6d44792a61cbba84db7a008' #\"<your training key>\" \n",
    "prediction_key = 'e1b14ec870914e70b17ea7732a43b3b9' #\"<your prediction key>\" \n",
    "prediction_resource_id = '/subscriptions/9a37f675-345c-4dd8-baad-4b7cf2748b3f/resourceGroups/CogAI/providers/Microsoft.CognitiveServices/accounts/CVpre' #\"<your prediction resource id>\" \n",
    "publish_iteration_name = \"detectModel\"\n",
    "\n",
    "trainer = CustomVisionTrainingClient(training_key, endpoint=train_ENDPOINT)\n",
    "\n",
    "# Find the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\n",
    "\n",
    "# Create a new project\n",
    "print (\"Creating project...\")\n",
    "project = trainer.create_project(\"My Detection Project\", domain_id=obj_detection_domain.id)\n",
    "\n",
    "# Make two tags in the new project\n",
    "fork_tag = trainer.create_tag(project.id, \"fork\")\n",
    "scissors_tag = trainer.create_tag(project.id, \"scissors\")\n",
    "\n",
    "fork_image_regions = {\n",
    "    \"fork_1\": [ 0.145833328, 0.3509314, 0.5894608, 0.238562092 ],\n",
    "    \"fork_2\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"fork_3\": [ 0.09191177, 0.0682516545, 0.757352948, 0.6143791 ],\n",
    "    \"fork_4\": [ 0.254901975, 0.185898721, 0.5232843, 0.594771266 ],\n",
    "    \"fork_5\": [ 0.2365196, 0.128709182, 0.5845588, 0.71405226 ],\n",
    "    \"fork_6\": [ 0.115196079, 0.133611143, 0.676470637, 0.6993464 ],\n",
    "    \"fork_7\": [ 0.164215669, 0.31008172, 0.767156839, 0.410130739 ],\n",
    "    \"fork_8\": [ 0.118872553, 0.318251669, 0.817401946, 0.225490168 ],\n",
    "    \"fork_9\": [ 0.18259804, 0.2136765, 0.6335784, 0.643790841 ],\n",
    "    \"fork_10\": [ 0.05269608, 0.282303959, 0.8088235, 0.452614367 ],\n",
    "    \"fork_11\": [ 0.05759804, 0.0894935, 0.9007353, 0.3251634 ],\n",
    "    \"fork_12\": [ 0.3345588, 0.07315363, 0.375, 0.9150327 ],\n",
    "    \"fork_13\": [ 0.269607842, 0.194068655, 0.4093137, 0.6732026 ],\n",
    "    \"fork_14\": [ 0.143382356, 0.218578458, 0.7977941, 0.295751631 ],\n",
    "    \"fork_15\": [ 0.19240196, 0.0633497, 0.5710784, 0.8398692 ],\n",
    "    \"fork_16\": [ 0.140931368, 0.480016381, 0.6838235, 0.240196079 ],\n",
    "    \"fork_17\": [ 0.305147052, 0.2512582, 0.4791667, 0.5408496 ],\n",
    "    \"fork_18\": [ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "    \"fork_19\": [ 0.219362751, 0.141781077, 0.5919118, 0.6683006 ],\n",
    "    \"fork_20\": [ 0.180147052, 0.239820287, 0.6887255, 0.235294119 ]\n",
    "}\n",
    "\n",
    "scissors_image_regions = {\n",
    "    \"scissors_1\": [ 0.4007353, 0.194068655, 0.259803921, 0.6617647 ],\n",
    "    \"scissors_2\": [ 0.426470578, 0.185898721, 0.172794119, 0.5539216 ],\n",
    "    \"scissors_3\": [ 0.289215684, 0.259428144, 0.403186262, 0.421568632 ],\n",
    "    \"scissors_4\": [ 0.343137264, 0.105833367, 0.332107842, 0.8055556 ],\n",
    "    \"scissors_5\": [ 0.3125, 0.09766343, 0.435049027, 0.71405226 ],\n",
    "    \"scissors_6\": [ 0.379901975, 0.24308826, 0.32107842, 0.5718954 ],\n",
    "    \"scissors_7\": [ 0.341911763, 0.20714055, 0.3137255, 0.6356209 ],\n",
    "    \"scissors_8\": [ 0.231617644, 0.08459154, 0.504901946, 0.8480392 ],\n",
    "    \"scissors_9\": [ 0.170343131, 0.332957536, 0.767156839, 0.403594762 ],\n",
    "    \"scissors_10\": [ 0.204656869, 0.120539248, 0.5245098, 0.743464053 ],\n",
    "    \"scissors_11\": [ 0.05514706, 0.159754932, 0.799019635, 0.730392158 ],\n",
    "    \"scissors_12\": [ 0.265931368, 0.169558853, 0.5061275, 0.606209159 ],\n",
    "    \"scissors_13\": [ 0.241421565, 0.184264734, 0.448529422, 0.6830065 ],\n",
    "    \"scissors_14\": [ 0.05759804, 0.05027781, 0.75, 0.882352948 ],\n",
    "    \"scissors_15\": [ 0.191176474, 0.169558853, 0.6936275, 0.6748366 ],\n",
    "    \"scissors_16\": [ 0.1004902, 0.279036, 0.6911765, 0.477124184 ],\n",
    "    \"scissors_17\": [ 0.2720588, 0.131977156, 0.4987745, 0.6911765 ],\n",
    "    \"scissors_18\": [ 0.180147052, 0.112369314, 0.6262255, 0.6666667 ],\n",
    "    \"scissors_19\": [ 0.333333343, 0.0274019931, 0.443627447, 0.852941155 ],\n",
    "    \"scissors_20\": [ 0.158088237, 0.04047389, 0.6691176, 0.843137264 ]\n",
    "}\n",
    "\n",
    "# Update this with the path to where you downloaded the images.\n",
    "base_image_url = os.getcwd() #'' #\"<path to repo directory>/cognitive-services-python-sdk-samples/samples/vision/\"\n",
    "#https://github.com/Azure-Samples/cognitive-services-python-sdk-samples/tree/master/samples/vision/images\n",
    "\n",
    "# Go through the data table above and create the images\n",
    "print (\"Adding images...\")\n",
    "tagged_images_with_regions = []\n",
    "\n",
    "for file_name in fork_image_regions.keys():\n",
    "    x,y,w,h = fork_image_regions[file_name]\n",
    "    regions = [ Region(tag_id=fork_tag.id, left=x,top=y,width=w,height=h) ]\n",
    "\n",
    "    with open(base_image_url + \"/sdk_images/fork/\" + file_name + \".jpg\", mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=regions))\n",
    "\n",
    "for file_name in scissors_image_regions.keys():\n",
    "    x,y,w,h = scissors_image_regions[file_name]\n",
    "    regions = [ Region(tag_id=scissors_tag.id, left=x,top=y,width=w,height=h) ]\n",
    "\n",
    "    with open(base_image_url + \"/sdk_images/scissors/\" + file_name + \".jpg\", mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=regions))\n",
    "\n",
    "upload_result = trainer.create_images_from_files(project.id, images=tagged_images_with_regions)\n",
    "if not upload_result.is_batch_successful:\n",
    "    print(\"Image batch upload failed.\")\n",
    "    for image in upload_result.images:\n",
    "        print(\"Image status: \", image.status)\n",
    "    exit(-1)\n",
    "    \n",
    "print (\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(1)\n",
    "\n",
    "# The iteration is now trained. Publish it to the project endpoint\n",
    "trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)\n",
    "print (\"Done!\")\n",
    "\n",
    "\n",
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "predictor = CustomVisionPredictionClient(prediction_key, endpoint=predi_ENDPOINT)\n",
    "\n",
    "# Open the sample image and get back the prediction results.\n",
    "with open(base_image_url + \"/sdK_images/Test/test_od_image.jpg\", mode=\"rb\") as test_data:\n",
    "    results = predictor.detect_image(project.id, publish_iteration_name, test_data)\n",
    "\n",
    "# Display the results.    \n",
    "for prediction in results.predictions:\n",
    "    print(\"\\t\" + prediction.tag_name + \": {0:.2f}% bbox.left = {1:.2f}, bbox.top = {2:.2f}, bbox.width = {3:.2f}, bbox.height = {4:.2f}\".format(prediction.probability * 100, prediction.bounding_box.left, prediction.bounding_box.top, prediction.bounding_box.width, prediction.bounding_box.height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Your Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project...\n"
     ]
    },
    {
     "ename": "CustomVisionErrorException",
     "evalue": "Exceeds 2 projects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCustomVisionErrorException\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6f5db901b275>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Create a new project\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating project...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mproject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_project\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"My Detection Project\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdomain_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj_detection_domain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Make two tags in the new project\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Azure\\lib\\site-packages\\azure\\cognitiveservices\\vision\\customvision\\training\\operations\\_custom_vision_training_client_operations.py\u001b[0m in \u001b[0;36mcreate_project\u001b[1;34m(self, name, description, domain_id, classification_type, target_export_platforms, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCustomVisionErrorException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCustomVisionErrorException\u001b[0m: Exceeds 2 projects"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch,ImageFileCreateEntry, Region\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "# ENDPOINT = #\"<your API endpoint>\" \n",
    "train_ENDPOINT = 'https://aien008.cognitiveservices.azure.com/' #\"<your API endpoint>\" \n",
    "predi_ENDPOINT = 'https://aien008-prediction.cognitiveservices.azure.com/ ' #\"<your API endpoint>\" \n",
    "\n",
    "# Replace with a valid key\n",
    "training_key = 'c7d8714403e84307a87df09fec63d839' #\"<your training key>\" \n",
    "prediction_key = '6e835f272a14401e8cc69b1f07b63fd3' #\"<your prediction key>\" \n",
    "prediction_resource_id = '/subscriptions/f4af6894-b651-439a-b300-ff1117ea824b/resourceGroups/AIEN08/providers/Microsoft.CognitiveServices/accounts/AIEN008-Prediction' #\"<your prediction resource id>\" \n",
    "publish_iteration_name = \"detectModel\"\n",
    "\n",
    "#trainer = CustomVisionTrainingClient(training_key, endpoint=train_ENDPOINT)\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(train_ENDPOINT, credentials)\n",
    "\n",
    "# Find the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\n",
    "\n",
    "# Create a new project\n",
    "print (\"Creating project...\")\n",
    "project = trainer.create_project(\"My Detection Project\", domain_id=obj_detection_domain.id)\n",
    "\n",
    "# Make two tags in the new project\n",
    "fork_tag = trainer.create_tag(project.id, \"fork\")\n",
    "scissors_tag = trainer.create_tag(project.id, \"scissors\")\n",
    "\n",
    "fork_image_regions = {\n",
    "    \"fork_1\": [ 0.145833328, 0.3509314, 0.5894608, 0.238562092 ],\n",
    "    \"fork_2\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"fork_3\": [ 0.09191177, 0.0682516545, 0.757352948, 0.6143791 ],\n",
    "    \"fork_4\": [ 0.254901975, 0.185898721, 0.5232843, 0.594771266 ],\n",
    "    \"fork_5\": [ 0.2365196, 0.128709182, 0.5845588, 0.71405226 ],\n",
    "    \"fork_6\": [ 0.115196079, 0.133611143, 0.676470637, 0.6993464 ],\n",
    "    \"fork_7\": [ 0.164215669, 0.31008172, 0.767156839, 0.410130739 ],\n",
    "    \"fork_8\": [ 0.118872553, 0.318251669, 0.817401946, 0.225490168 ],\n",
    "    \"fork_9\": [ 0.18259804, 0.2136765, 0.6335784, 0.643790841 ],\n",
    "    \"fork_10\": [ 0.05269608, 0.282303959, 0.8088235, 0.452614367 ],\n",
    "    \"fork_11\": [ 0.05759804, 0.0894935, 0.9007353, 0.3251634 ],\n",
    "    \"fork_12\": [ 0.3345588, 0.07315363, 0.375, 0.9150327 ],\n",
    "    \"fork_13\": [ 0.269607842, 0.194068655, 0.4093137, 0.6732026 ],\n",
    "    \"fork_14\": [ 0.143382356, 0.218578458, 0.7977941, 0.295751631 ],\n",
    "    \"fork_15\": [ 0.19240196, 0.0633497, 0.5710784, 0.8398692 ],\n",
    "    \"fork_16\": [ 0.140931368, 0.480016381, 0.6838235, 0.240196079 ],\n",
    "    \"fork_17\": [ 0.305147052, 0.2512582, 0.4791667, 0.5408496 ],\n",
    "    \"fork_18\": [ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "    \"fork_19\": [ 0.219362751, 0.141781077, 0.5919118, 0.6683006 ],\n",
    "    \"fork_20\": [ 0.180147052, 0.239820287, 0.6887255, 0.235294119 ]\n",
    "}\n",
    "\n",
    "scissors_image_regions = {\n",
    "    \"scissors_1\": [ 0.4007353, 0.194068655, 0.259803921, 0.6617647 ],\n",
    "    \"scissors_2\": [ 0.426470578, 0.185898721, 0.172794119, 0.5539216 ],\n",
    "    \"scissors_3\": [ 0.289215684, 0.259428144, 0.403186262, 0.421568632 ],\n",
    "    \"scissors_4\": [ 0.343137264, 0.105833367, 0.332107842, 0.8055556 ],\n",
    "    \"scissors_5\": [ 0.3125, 0.09766343, 0.435049027, 0.71405226 ],\n",
    "    \"scissors_6\": [ 0.379901975, 0.24308826, 0.32107842, 0.5718954 ],\n",
    "    \"scissors_7\": [ 0.341911763, 0.20714055, 0.3137255, 0.6356209 ],\n",
    "    \"scissors_8\": [ 0.231617644, 0.08459154, 0.504901946, 0.8480392 ],\n",
    "    \"scissors_9\": [ 0.170343131, 0.332957536, 0.767156839, 0.403594762 ],\n",
    "    \"scissors_10\": [ 0.204656869, 0.120539248, 0.5245098, 0.743464053 ],\n",
    "    \"scissors_11\": [ 0.05514706, 0.159754932, 0.799019635, 0.730392158 ],\n",
    "    \"scissors_12\": [ 0.265931368, 0.169558853, 0.5061275, 0.606209159 ],\n",
    "    \"scissors_13\": [ 0.241421565, 0.184264734, 0.448529422, 0.6830065 ],\n",
    "    \"scissors_14\": [ 0.05759804, 0.05027781, 0.75, 0.882352948 ],\n",
    "    \"scissors_15\": [ 0.191176474, 0.169558853, 0.6936275, 0.6748366 ],\n",
    "    \"scissors_16\": [ 0.1004902, 0.279036, 0.6911765, 0.477124184 ],\n",
    "    \"scissors_17\": [ 0.2720588, 0.131977156, 0.4987745, 0.6911765 ],\n",
    "    \"scissors_18\": [ 0.180147052, 0.112369314, 0.6262255, 0.6666667 ],\n",
    "    \"scissors_19\": [ 0.333333343, 0.0274019931, 0.443627447, 0.852941155 ],\n",
    "    \"scissors_20\": [ 0.158088237, 0.04047389, 0.6691176, 0.843137264 ]\n",
    "}\n",
    "\n",
    "# Update this with the path to where you downloaded the images.\n",
    "base_image_url = os.getcwd() #'' #\"<path to repo directory>/cognitive-services-python-sdk-samples/samples/vision/\"\n",
    "#https://github.com/Azure-Samples/cognitive-services-python-sdk-samples/tree/master/samples/vision/images\n",
    "\n",
    "# Go through the data table above and create the images\n",
    "print (\"Adding images...\")\n",
    "tagged_images_with_regions = []\n",
    "\n",
    "for file_name in fork_image_regions.keys():\n",
    "    x,y,w,h = fork_image_regions[file_name]\n",
    "    regions = [ Region(tag_id=fork_tag.id, left=x,top=y,width=w,height=h) ]\n",
    "\n",
    "    with open(base_image_url + \"/sdk_images/fork/\" + file_name + \".jpg\", mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=regions))\n",
    "\n",
    "for file_name in scissors_image_regions.keys():\n",
    "    x,y,w,h = scissors_image_regions[file_name]\n",
    "    regions = [ Region(tag_id=scissors_tag.id, left=x,top=y,width=w,height=h) ]\n",
    "\n",
    "    with open(base_image_url + \"/sdk_images/scissors/\" + file_name + \".jpg\", mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=regions))\n",
    "\n",
    "\n",
    "upload_result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=tagged_images_with_regions))\n",
    "\n",
    "if not upload_result.is_batch_successful:\n",
    "    print(\"Image batch upload failed.\")\n",
    "    for image in upload_result.images:\n",
    "        print(\"Image status: \", image.status)\n",
    "    exit(-1)\n",
    "    \n",
    "print (\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(1)\n",
    "\n",
    "# The iteration is now trained. Publish it to the project endpoint\n",
    "trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)\n",
    "print (\"Done!\")\n",
    "\n",
    "\n",
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(predi_ENDPOINT, prediction_credentials)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Open the sample image and get back the prediction results.\n",
    "with open(base_image_url + \"/sdK_images/Test/test_od_image.jpg\", mode=\"rb\") as test_data:\n",
    "    results = predictor.detect_image(project.id, publish_iteration_name, test_data)\n",
    "\n",
    "# Display the results.    \n",
    "for prediction in results.predictions:\n",
    "    print(\"\\t\" + prediction.tag_name + \": {0:.2f}% bbox.left = {1:.2f}, bbox.top = {2:.2f}, bbox.width = {3:.2f}, bbox.height = {4:.2f}\".format(prediction.probability * 100, prediction.bounding_box.left, prediction.bounding_box.top, prediction.bounding_box.width, prediction.bounding_box.height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
